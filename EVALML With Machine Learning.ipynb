{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not infer format, so each element will be parsed individually\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading The Dataset\n",
    "- We can also read the dataset from csv\n",
    "- then convert to datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Number of Features\n",
      "Numeric                  30\n",
      "\n",
      "Number of training examples: 569\n",
      "Targets\n",
      "benign       62.74%\n",
      "malignant    37.26%\n",
      "Name: count, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import evalml\n",
    "X, y = evalml.demos.load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>11.04</td>\n",
       "      <td>14.93</td>\n",
       "      <td>70.67</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>0.07079</td>\n",
       "      <td>0.03546</td>\n",
       "      <td>0.020740</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.06246</td>\n",
       "      <td>...</td>\n",
       "      <td>12.090</td>\n",
       "      <td>20.83</td>\n",
       "      <td>79.73</td>\n",
       "      <td>447.1</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.15530</td>\n",
       "      <td>0.06754</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.07287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10.75</td>\n",
       "      <td>14.97</td>\n",
       "      <td>68.26</td>\n",
       "      <td>355.3</td>\n",
       "      <td>0.07793</td>\n",
       "      <td>0.05139</td>\n",
       "      <td>0.02251</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950</td>\n",
       "      <td>20.72</td>\n",
       "      <td>77.79</td>\n",
       "      <td>441.2</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.09755</td>\n",
       "      <td>0.03413</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.06769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>11.71</td>\n",
       "      <td>16.67</td>\n",
       "      <td>74.72</td>\n",
       "      <td>423.6</td>\n",
       "      <td>0.10510</td>\n",
       "      <td>0.06095</td>\n",
       "      <td>0.03592</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.05945</td>\n",
       "      <td>...</td>\n",
       "      <td>13.330</td>\n",
       "      <td>25.48</td>\n",
       "      <td>86.16</td>\n",
       "      <td>546.7</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.10460</td>\n",
       "      <td>0.06968</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.07343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>8.95</td>\n",
       "      <td>15.76</td>\n",
       "      <td>58.74</td>\n",
       "      <td>245.2</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>0.09263</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.07163</td>\n",
       "      <td>...</td>\n",
       "      <td>9.414</td>\n",
       "      <td>17.07</td>\n",
       "      <td>63.34</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.1179</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.15440</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "381        11.04         14.93           70.67      372.7          0.07987   \n",
       "144        10.75         14.97           68.26      355.3          0.07793   \n",
       "136        11.71         16.67           74.72      423.6          0.10510   \n",
       "116         8.95         15.76           58.74      245.2          0.09462   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "381           0.07079         0.03546             0.020740         0.2003   \n",
       "144           0.05139         0.02251             0.007875         0.1399   \n",
       "136           0.06095         0.03592             0.026000         0.1339   \n",
       "116           0.12430         0.09263             0.023080         0.1305   \n",
       "567           0.27700         0.35140             0.152000         0.2397   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "381                 0.06246  ...        12.090          20.83   \n",
       "144                 0.05688  ...        11.950          20.72   \n",
       "136                 0.05945  ...        13.330          25.48   \n",
       "116                 0.07163  ...         9.414          17.07   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "381            79.73       447.1            0.1095             0.1982   \n",
       "144            77.79       441.2            0.1076             0.1223   \n",
       "136            86.16       546.7            0.1271             0.1028   \n",
       "116            63.34       270.0            0.1179             0.1879   \n",
       "567           184.60      1821.0            0.1650             0.8681   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "381          0.15530               0.06754          0.3202   \n",
       "144          0.09755               0.03413          0.2300   \n",
       "136          0.10460               0.06968          0.1712   \n",
       "116          0.15440               0.03846          0.1652   \n",
       "567          0.93870               0.26500          0.4087   \n",
       "\n",
       "     worst fractal dimension  \n",
       "381                  0.07287  \n",
       "144                  0.06769  \n",
       "136                  0.07343  \n",
       "116                  0.07722  \n",
       "567                  0.12400  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the AutoML to select the best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ProblemTypes.BINARY: 'binary'>,\n",
       " <ProblemTypes.MULTICLASS: 'multiclass'>,\n",
       " <ProblemTypes.REGRESSION: 'regression'>,\n",
       " <ProblemTypes.TIME_SERIES_REGRESSION: 'time series regression'>,\n",
       " <ProblemTypes.TIME_SERIES_BINARY: 'time series binary'>,\n",
       " <ProblemTypes.TIME_SERIES_MULTICLASS: 'time series multiclass'>,\n",
       " <ProblemTypes.MULTISERIES_TIME_SERIES_REGRESSION: 'multiseries time series regression'>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evalml\n",
    "evalml.problem_types.ProblemTypes.all_problem_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'Random Forest Classifier w/ Label Encoder + Imputer + RF Classifier Select From Model': 3.1075472831726074,\n",
       "  'Total time of batch': 3.2621190547943115},\n",
       " 2: {'LightGBM Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 2.014968156814575,\n",
       "  'Extra Trees Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 2.3147449493408203,\n",
       "  'Elastic Net Classifier w/ Label Encoder + Imputer + Standard Scaler + Select Columns Transformer': 1.9169294834136963,\n",
       "  'XGBoost Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 2.0119779109954834,\n",
       "  'Logistic Regression Classifier w/ Label Encoder + Imputer + Standard Scaler + Select Columns Transformer': 6.585797548294067,\n",
       "  'Total time of batch': 15.540068864822388}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evalml.automl import AutoMLSearch\n",
    "automl = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>search_order</th>\n",
       "      <th>ranking_score</th>\n",
       "      <th>mean_cv_score</th>\n",
       "      <th>standard_deviation_cv_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Logistic Regression Classifier w/ Label Encode...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.033734</td>\n",
       "      <td>99.169406</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Elastic Net Classifier w/ Label Encoder + Impu...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114153</td>\n",
       "      <td>0.114153</td>\n",
       "      <td>0.031724</td>\n",
       "      <td>99.152325</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Random Forest Classifier w/ Label Encoder + Im...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126770</td>\n",
       "      <td>0.126770</td>\n",
       "      <td>0.035172</td>\n",
       "      <td>99.058640</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Extra Trees Classifier w/ Label Encoder + Impu...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.150551</td>\n",
       "      <td>0.150551</td>\n",
       "      <td>0.034153</td>\n",
       "      <td>98.882044</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost Classifier w/ Label Encoder + Imputer ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.150885</td>\n",
       "      <td>0.150885</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>98.879567</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM Classifier w/ Label Encoder + Imputer...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.194301</td>\n",
       "      <td>0.194301</td>\n",
       "      <td>0.052339</td>\n",
       "      <td>98.557171</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>0</td>\n",
       "      <td>13.466641</td>\n",
       "      <td>13.466641</td>\n",
       "      <td>0.086133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      pipeline_name  search_order  \\\n",
       "0   6  Logistic Regression Classifier w/ Label Encode...             6   \n",
       "1   4  Elastic Net Classifier w/ Label Encoder + Impu...             4   \n",
       "2   1  Random Forest Classifier w/ Label Encoder + Im...             1   \n",
       "3   3  Extra Trees Classifier w/ Label Encoder + Impu...             3   \n",
       "4   5  XGBoost Classifier w/ Label Encoder + Imputer ...             5   \n",
       "5   2  LightGBM Classifier w/ Label Encoder + Imputer...             2   \n",
       "6   0       Mode Baseline Binary Classification Pipeline             0   \n",
       "\n",
       "   ranking_score  mean_cv_score  standard_deviation_cv_score  \\\n",
       "0       0.111853       0.111853                     0.033734   \n",
       "1       0.114153       0.114153                     0.031724   \n",
       "2       0.126770       0.126770                     0.035172   \n",
       "3       0.150551       0.150551                     0.034153   \n",
       "4       0.150885       0.150885                     0.046259   \n",
       "5       0.194301       0.194301                     0.052339   \n",
       "6      13.466641      13.466641                     0.086133   \n",
       "\n",
       "   percent_better_than_baseline  high_variance_cv  \\\n",
       "0                     99.169406             False   \n",
       "1                     99.152325             False   \n",
       "2                     99.058640             False   \n",
       "3                     98.882044             False   \n",
       "4                     98.879567             False   \n",
       "5                     98.557171             False   \n",
       "6                      0.000000             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "1  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "2  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "3  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "4  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "5  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "6  {'Label Encoder': {'positive_label': None}, 'B...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting The Best Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = BinaryClassificationPipeline(component_graph={'Label Encoder': ['Label Encoder', 'X', 'y'], 'Imputer': ['Imputer', 'X', 'Label Encoder.y'], 'Standard Scaler': ['Standard Scaler', 'Imputer.x', 'Label Encoder.y'], 'Select Columns Transformer': ['Select Columns Transformer', 'Standard Scaler.x', 'Label Encoder.y'], 'Logistic Regression Classifier': ['Logistic Regression Classifier', 'Select Columns Transformer.x', 'Label Encoder.y']}, parameters={'Label Encoder':{'positive_label': None}, 'Imputer':{'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'mean', 'boolean_impute_strategy': 'most_frequent', 'categorical_fill_value': None, 'numeric_fill_value': None, 'boolean_fill_value': None}, 'Select Columns Transformer':{'columns': ['mean radius', 'mean perimeter', 'mean area', 'mean concavity', 'mean concave points', 'radius error', 'perimeter error', 'area error', 'smoothness error', 'worst radius', 'worst perimeter', 'worst area', 'worst concave points', 'worst symmetry', 'worst fractal dimension']}, 'Logistic Regression Classifier':{'penalty': 'l2', 'C': 1.0, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'lbfgs'}}, random_seed=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline=automl.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Check the detailed desscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************************************************************************\n",
      "* Logistic Regression Classifier w/ Label Encoder + Imputer + Standard Scaler + Select Columns Transformer *\n",
      "************************************************************************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: Linear\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Label Encoder\n",
      "\t * positive_label : None\n",
      "2. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * boolean_impute_strategy : most_frequent\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "\t * boolean_fill_value : None\n",
      "3. Standard Scaler\n",
      "4. Select Columns Transformer\n",
      "\t * columns : ['mean radius', 'mean perimeter', 'mean area', 'mean concavity', 'mean concave points', 'radius error', 'perimeter error', 'area error', 'smoothness error', 'worst radius', 'worst perimeter', 'worst area', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "5. Logistic Regression Classifier\n",
      "\t * penalty : l2\n",
      "\t * C : 1.0\n",
      "\t * n_jobs : -1\n",
      "\t * multi_class : auto\n",
      "\t * solver : lbfgs\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for binary problems.\n",
      "Total training time (including CV): 6.6 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Binary  MCC Binary  Gini   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.075       0.930 0.989 0.995      0.948 0.957                     0.967            0.967        303          152\n",
      "1                      0.118       0.848 0.985 0.992      0.979 0.895                     0.907            0.928        303          152\n",
      "2                      0.142       0.849 0.971 0.985      0.869 0.906                     0.931            0.927        304          151\n",
      "mean                   0.112       0.876 0.982 0.991      0.932 0.919                     0.935            0.941          -            -\n",
      "std                    0.034       0.047 0.010 0.005      0.057 0.033                     0.030            0.023          -            -\n",
      "coef of var            0.302       0.054 0.010 0.005      0.061 0.036                     0.032            0.024          -            -\n"
     ]
    }
   ],
   "source": [
    "automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AUC', 0.9828042328042328),\n",
       "             ('F1', 0.9069767441860465),\n",
       "             ('Precision', 0.8863636363636364),\n",
       "             ('Recall', 0.9285714285714286)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluate on hold out data\n",
    "best_pipeline.score(X_test, y_test, objectives=[\"auc\",\"f1\",\"Precision\",\"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also optimize for a problem specific objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'Random Forest Classifier w/ Label Encoder + Imputer + RF Classifier Select From Model': 3.215963840484619,\n",
       "  'Total time of batch': 3.36702036857605}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_auc = AutoMLSearch(X_train=X_train, y_train=y_train,\n",
    "                          problem_type='binary',\n",
    "                          objective='auc',\n",
    "                          additional_objectives=['f1', 'precision'],\n",
    "                          max_batches=1,\n",
    "                          optimize_thresholds=True)\n",
    "\n",
    "automl_auc.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>search_order</th>\n",
       "      <th>ranking_score</th>\n",
       "      <th>mean_cv_score</th>\n",
       "      <th>standard_deviation_cv_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Random Forest Classifier w/ Label Encoder + Im...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989686</td>\n",
       "      <td>0.989686</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>48.968584</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      pipeline_name  search_order  \\\n",
       "0   1  Random Forest Classifier w/ Label Encoder + Im...             1   \n",
       "1   0       Mode Baseline Binary Classification Pipeline             0   \n",
       "\n",
       "   ranking_score  mean_cv_score  standard_deviation_cv_score  \\\n",
       "0       0.989686       0.989686                     0.006053   \n",
       "1       0.500000       0.500000                     0.000000   \n",
       "\n",
       "   percent_better_than_baseline  high_variance_cv  \\\n",
       "0                     48.968584             False   \n",
       "1                      0.000000             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "1  {'Label Encoder': {'positive_label': None}, 'B...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_auc.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************************\n",
      "* Random Forest Classifier w/ Label Encoder + Imputer + RF Classifier Select From Model *\n",
      "*****************************************************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: Random Forest\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Label Encoder\n",
      "\t * positive_label : None\n",
      "2. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * boolean_impute_strategy : most_frequent\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "\t * boolean_fill_value : None\n",
      "3. RF Classifier Select From Model\n",
      "\t * number_features : None\n",
      "\t * n_estimators : 10\n",
      "\t * max_depth : None\n",
      "\t * percent_features : 0.5\n",
      "\t * threshold : median\n",
      "\t * n_jobs : -1\n",
      "4. Random Forest Classifier\n",
      "\t * n_estimators : 100\n",
      "\t * max_depth : 6\n",
      "\t * n_jobs : -1\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for binary problems.\n",
      "Total training time (including CV): 3.2 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "              AUC    F1  Precision # Training # Validation\n",
      "0           0.996 0.966      0.949        303          152\n",
      "1           0.990 0.904      0.897        303          152\n",
      "2           0.984 0.904      0.881        304          151\n",
      "mean        0.990 0.925      0.909          -            -\n",
      "std         0.006 0.035      0.036          -            -\n",
      "coef of var 0.006 0.038      0.039          -            -\n"
     ]
    }
   ],
   "source": [
    "automl_auc.describe_pipeline(automl_auc.rankings.iloc[0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline_auc = automl_auc.best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AUC', 0.9857804232804233)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the score on holdout data\n",
    "best_pipeline_auc.score(X_test, y_test,  objectives=[\"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline.save(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model=automl.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benign</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>9.927723e-01</td>\n",
       "      <td>0.007228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>9.632001e-01</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>8.978461e-01</td>\n",
       "      <td>0.102154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>9.762130e-01</td>\n",
       "      <td>0.023787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9.983410e-01</td>\n",
       "      <td>0.001659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>9.939219e-01</td>\n",
       "      <td>0.006078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>7.511339e-01</td>\n",
       "      <td>0.248866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>9.978193e-01</td>\n",
       "      <td>0.002181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.534423e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>9.995242e-01</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           benign  malignant\n",
       "477  9.927723e-01   0.007228\n",
       "558  9.632001e-01   0.036800\n",
       "537  8.978461e-01   0.102154\n",
       "322  9.762130e-01   0.023787\n",
       "474  9.983410e-01   0.001659\n",
       "..            ...        ...\n",
       "364  9.939219e-01   0.006078\n",
       "518  7.511339e-01   0.248866\n",
       "354  9.978193e-01   0.002181\n",
       "23   2.534423e-07   1.000000\n",
       "548  9.995242e-01   0.000476\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
